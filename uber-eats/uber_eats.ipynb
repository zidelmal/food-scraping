{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://www.ubereats.com/fr/location')\n",
    "soup = bs(r.content,\"html.parser\")\n",
    "dom = etree.HTML(str(soup))\n",
    "\n",
    "regions = dom.xpath('//*[@id=\"main-content\"]/div[2]/div')\n",
    "\n",
    "villes_lists = []\n",
    "for region in regions[1:]:\n",
    "    villes_lists.append(region.xpath('//div/div/a/@href'))\n",
    "\n",
    "flat_villes = list(dict.fromkeys(['https://www.ubereats.com'+ville for villes in villes_lists for ville in villes if ville.__contains__('location')==False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import time\n",
    "from datetime import datetime\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "prefs = {\"profile.default_content_setting_values.notifications\" : 2}\n",
    "chrome_options.add_experimental_option(\"prefs\",prefs)\n",
    "# chrome_options.add_argument('headless')\n",
    "# chrome_options.add_argument('window-size=0x0')\n",
    "#specify the path to msedgedriver.exe (download and save on your computer)\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for ville in flat_villes:\n",
    "    driver.get(ville)\n",
    "    restaurants = driver.find_elements(\n",
    "            by=By.XPATH, \n",
    "            value='//*[@id=\"main-content\"]/div[5]/div[2]/a'\n",
    "            )\n",
    "\n",
    "    informations = {\n",
    "        'url': [],\n",
    "        'name': [],\n",
    "        'categories': [],\n",
    "        'address': [],\n",
    "        \"rating\": [],\n",
    "        'promotion': []\n",
    "    }\n",
    "\n",
    "    for i, restaurant in enumerate(restaurants):\n",
    "        informations['url'].append(restaurant.get_attribute('href'))\n",
    "        informations['name'].append(driver.find_element(by=By.XPATH, value=f'//*[@id=\"main-content\"]/div[5]/div[2]/a[{i+1}]/div[2]/div[1]/h3').text.strip())\n",
    "        print(driver.find_element(by=By.XPATH, value=f'//*[@id=\"main-content\"]/div[5]/div[2]/a[{i+1}]/div[2]/div[1]/h3').text.strip())\n",
    "        # informations['delivery_time'].append(restaurant.find_element(by=By.XPATH, value='//div/div/div/div/div[1]/div/div[2]/div/span').text.strip(' min'))\n",
    "        # informations['delivery_price'].append(restaurant.find_element(by=By.XPATH, value='//div/div/div/div/div[1]/div/div[3]/div/span').text.strip('Frais de livraison : '))\n",
    "        informations['categories'].append(', '.join(driver.find_element(by=By.XPATH, value=f'//*[@id=\"main-content\"]/div[5]/div[2]/a[{i+1}]/div[2]/span').text.split(' â€¢ ')))\n",
    "        informations['address'].append(driver.find_element(by=By.XPATH, value=f'//*[@id=\"main-content\"]/div[5]/div[2]/a[{i+1}]/div[2]/div[2]/span[2]').text.strip())\n",
    "        informations['rating'].append(driver.find_element(by=By.XPATH, value=f'//*[@id=\"main-content\"]/div[5]/div[2]/a[{i+1}]/div[2]/div[1]/div').text.strip())\n",
    "        try:\n",
    "            informations['promotion'].append(driver.find_element(by=By.XPATH, value=f'//*[@id=\"main-content\"]/div[5]/div[2]/a[{i+1}]/div[1]/div/div').text.strip())\n",
    "        except:\n",
    "            informations['promotion'].append('')\n",
    "    \n",
    "    data = pd.concat([data, pd.DataFrame(informations)], ignore_index=True)\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_elements(\n",
    "            by=By.XPATH, \n",
    "            value='//*[@id=\"main-content\"]/div[5]/div[2]/a'\n",
    "            )[0].get_attribute('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant.find_element(by=By.XPATH, value='//div[2]/div[1]/h3').text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants = driver.find_elements(\n",
    "            by=By.XPATH, \n",
    "            value='//*[@id=\"main-content\"]/div[5]/div[2]/a'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
