{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import time\n",
    "from datetime import datetime\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "prefs = {\"profile.default_content_setting_values.notifications\" : 2}\n",
    "chrome_options.add_experimental_option(\"prefs\",prefs)\n",
    "# chrome_options.add_argument('headless')\n",
    "# chrome_options.add_argument('window-size=0x0')\n",
    "#specify the path to msedgedriver.exe (download and save on your computer)\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/yassir/Documents/work/yassir-scraping/uber-eats/uberEats_before.csv')\n",
    "data = data.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame()\n",
    "df = pd.read_csv('uberEats_in.csv')\n",
    "for i, row in data[559:].iterrows():\n",
    "    driver.get(row['url'])\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, value='//*[@id=\"wrapper\"]/div[4]/div/div/div[2]/div[2]/button').click()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        info = eval(driver.find_element(By.XPATH, value='//*[@id=\"main-content\"]/script').get_attribute('innerHTML'))\n",
    "\n",
    "        def rating_error(info):\n",
    "            try:\n",
    "                return info['aggregateRating']['reviewCount']\n",
    "            except:\n",
    "                return ''\n",
    "\n",
    "        informations = {\n",
    "        'url': [driver.current_url],\n",
    "        'tota_ratings': [rating_error(info)],\n",
    "        'address': [info['address']['streetAddress']+', '+info['address']['addressRegion']+' '+info['address']['postalCode']],\n",
    "        \"latitude\":[info['geo']['latitude']],\n",
    "        \"longitude\":[info['geo']['longitude']],\n",
    "        'phone_number' : [info['telephone']],\n",
    "        'category': [info['servesCuisine']],\n",
    "        'program':[info['openingHoursSpecification']],\n",
    "        'menu': [info['hasMenu']]\n",
    "        }\n",
    "\n",
    "        # def food_rating_error(icat, iprod):\n",
    "        #     try:\n",
    "        #         return driver.find_element(By.XPATH, value=f'//*[@id=\"main-content\"]/div[5]/div/div[4]/ul/li[{icat+1}]/ul/li[{iprod+1}]/div/div/div[2]/div[3]').text.strip()\n",
    "        #     except:\n",
    "        #         return ''\n",
    "\n",
    "        # def image_error(icat, iprod):\n",
    "        #     try:\n",
    "        #         return driver.find_element(By.XPATH, value=f'//*[@id=\"main-content\"]/div[5]/div/div[4]/ul/li[{icat+1}]/ul/li[{iprod+1}]/div/div/div[1]/div[1]/div[1]/picture/img').get_attribute('src')\n",
    "        #     except:\n",
    "        #         return ''\n",
    "            \n",
    "        # for icat, category in enumerate(driver.find_elements(By.XPATH, value='//*[@id=\"main-content\"]/div[5]/div/div[4]/ul/li')):\n",
    "        #     informations['food_category'].append(driver.find_element(By.XPATH, f'//*[@id=\"main-content\"]/div[5]/div/div[4]/ul/li[{icat+1}]/h3').text.strip())\n",
    "        #     for iprod, product in enumerate(driver.find_elements(By.XPATH, value=f'//*[@id=\"main-content\"]/div[5]/div/div[4]/ul/li[{icat+1}]/ul/li')):\n",
    "        #         informations['menu'].append({'name': driver.find_element(By.XPATH, value=f'//*[@id=\"main-content\"]/div[5]/div/div[4]/ul/li[{icat+1}]/ul/li[{iprod+1}]/div/div/div[2]/div[1]/span').text.strip(),\n",
    "        #                                         'price': driver.find_element(By.XPATH, value=f'//*[@id=\"main-content\"]/div[5]/div/div[4]/ul/li[{icat+1}]/ul/li[{iprod+1}]/div/div/div[2]/div[2]/div/span').text.strip(' â‚¬'),\n",
    "        #                                         'product_rating': food_rating_error(icat, iprod),\n",
    "        #                                         'image': image_error(icat, iprod)})\n",
    "        \n",
    "        df = pd.concat([df, pd.DataFrame(informations)], ignore_index=True)\n",
    "        df.to_csv('uberEats_marseille_in.csv', index=False)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(df, how='left', on='url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('uberEats_marseille.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
